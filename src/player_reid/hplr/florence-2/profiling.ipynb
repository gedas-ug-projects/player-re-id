{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import logging\n",
    "import random\n",
    "import warnings\n",
    "import argparse\n",
    "import cProfile\n",
    "import pstats\n",
    "import torch.multiprocessing as mp\n",
    "import time\n",
    "from typing import Optional, List\n",
    "\n",
    "from argparse import Namespace\n",
    "from glob import glob\n",
    "from PIL import Image, ImageOps\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from optimum.bettertransformer import BetterTransformer\n",
    "from optimum.onnxruntime import ORTModelForCausalLM\n",
    "from optimum.onnxruntime.configuration import AutoQuantizationConfig\n",
    "from optimum.onnxruntime import ORTOptimizer\n",
    "\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "TOTAL_GPUS = 8\n",
    "BOOTSTRAPS = 3\n",
    "\n",
    "# TODO: Optimize prompt length?\n",
    "PROMPT = \"\"\"Identify the jersey number of the basketball player in the frame. If none, return None. Output only the digits:\n",
    "<jersey_number>\n",
    "[EOS]\"\"\"\n",
    "\n",
    "# TODO:\n",
    "# 1. Optimum -- NO SUPPORT\n",
    "# 2. to_bettertransformer() -- NO SUPPORT\n",
    "# 3. torch.backends.cuda.sdp_kernel\n",
    "# 4. tensorRT (no quantization): https://huggingface.co/docs/optimum/onnxruntime/usage_guides/gpu#accelerated-inference-on-nvidia-gpus\n",
    "# 5. autocast -- NO SPEEDUP vs. HALF()\n",
    "# 6. 4/8bit quantization -- NO SUPPORT\n",
    "# 7. # bootstraps 9 -> 3\n",
    "# 8. florence large -> florence-base\n",
    "# 9. export for onnx + onnx rt\n",
    "# 10. torch dataloader?\n",
    "# 11. paralellize data pre-processing w/ processor obj.\n",
    "\n",
    "\n",
    "def load_model_and_tokenizer(device: int = 0, args=None):\n",
    "    # compile_model = args.compile_model\n",
    "    # precision = args.precision\n",
    "    try:\n",
    "        logger.info(\"Loading model and tokenizer...\")\n",
    "        model = (\n",
    "            AutoModelForCausalLM.from_pretrained(\n",
    "                # \"microsoft/Florence-2-large-ft\",\n",
    "                \"microsoft/Florence-2-base-ft\",\n",
    "                trust_remote_code=True,\n",
    "                device_map=\"cuda\",\n",
    "            )\n",
    "            .eval()\n",
    "            .to(device)\n",
    "        )\n",
    "\n",
    "        # attempt to speed up inference by compiling model JIT\n",
    "        # if compile_model == \"True\":\n",
    "        #     logger.info(\"Compiling model...\")\n",
    "        #     model = torch.compile(model, mode=\"max-autotune\")\n",
    "        \n",
    "        # optimizer = ORTOptimizer.from_pretrained(model)\n",
    "        # quant_config = AutoQuantizationConfig.avx512_vnni()\n",
    "        # optimizer.optimize_model(\"onnx_model.onnx\", quantization_config=quant_config)\n",
    "\n",
    "        model = torch.compile(model)\n",
    "        processor = AutoProcessor.from_pretrained(\n",
    "            # \"microsoft/Florence-2-large-ft\", \n",
    "            \"microsoft/Florence-2-base-ft\", \n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "        return model, processor\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load model or tokenizer: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 17:11:53,605 - INFO - Loading model and tokenizer...\n",
      "2024-07-11 17:11:53,655 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-base-ft/resolve/main/config.json HTTP/11\" 200 0\n",
      "2024-07-11 17:11:53,711 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-base-ft/resolve/main/configuration_florence2.py HTTP/11\" 200 0\n",
      "2024-07-11 17:11:53,779 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-base-ft/resolve/main/modeling_florence2.py HTTP/11\" 200 0\n",
      "2024-07-11 17:11:53,878 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-base-ft/resolve/main/model.safetensors HTTP/11\" 404 0\n",
      "2024-07-11 17:14:45,040 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-base-ft/resolve/main/generation_config.json HTTP/11\" 404 0\n",
      "2024-07-11 17:14:45,110 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-base-ft/resolve/main/processor_config.json HTTP/11\" 404 0\n",
      "2024-07-11 17:14:45,167 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-base-ft/resolve/main/preprocessor_config.json HTTP/11\" 200 0\n",
      "2024-07-11 17:14:45,168 - DEBUG - Attempting to acquire lock 140574791188432 on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/85cd7be3568df661ad536b6ab20d59b08ba079ae.lock\n",
      "2024-07-11 17:14:45,169 - DEBUG - Lock 140574791188432 acquired on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/85cd7be3568df661ad536b6ab20d59b08ba079ae.lock\n",
      "2024-07-11 17:14:45,215 - DEBUG - https://huggingface.co:443 \"GET /microsoft/Florence-2-base-ft/resolve/main/preprocessor_config.json HTTP/11\" 200 806\n",
      "2024-07-11 17:14:45,218 - DEBUG - Attempting to release lock 140574791188432 on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/85cd7be3568df661ad536b6ab20d59b08ba079ae.lock\n",
      "2024-07-11 17:14:45,219 - DEBUG - Lock 140574791188432 released on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/85cd7be3568df661ad536b6ab20d59b08ba079ae.lock\n",
      "2024-07-11 17:14:45,269 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-base-ft/resolve/main/preprocessor_config.json HTTP/11\" 200 0\n",
      "2024-07-11 17:14:45,326 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-base-ft/resolve/main/processing_florence2.py HTTP/11\" 200 0\n",
      "2024-07-11 17:14:45,328 - DEBUG - Attempting to acquire lock 140574791181648 on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/e200735c73f7046c9897c13ac4a1e8536c209e59.lock\n",
      "2024-07-11 17:14:45,328 - DEBUG - Lock 140574791181648 acquired on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/e200735c73f7046c9897c13ac4a1e8536c209e59.lock\n",
      "2024-07-11 17:14:45,380 - DEBUG - https://huggingface.co:443 \"GET /microsoft/Florence-2-base-ft/resolve/main/processing_florence2.py HTTP/11\" 200 46372\n",
      "2024-07-11 17:14:45,381 - DEBUG - Attempting to release lock 140574791181648 on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/e200735c73f7046c9897c13ac4a1e8536c209e59.lock\n",
      "2024-07-11 17:14:45,382 - DEBUG - Lock 140574791181648 released on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/e200735c73f7046c9897c13ac4a1e8536c209e59.lock\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Florence-2-base-ft:\n",
      "- processing_florence2.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "2024-07-11 17:14:45,451 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-base-ft/resolve/main/preprocessor_config.json HTTP/11\" 200 0\n",
      "2024-07-11 17:14:45,498 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-base-ft/resolve/main/tokenizer_config.json HTTP/11\" 200 0\n",
      "2024-07-11 17:14:45,500 - DEBUG - Attempting to acquire lock 140574853411984 on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/44784bc58d4cb18d3549ad71e062efcf032d9ef5.lock\n",
      "2024-07-11 17:14:45,501 - DEBUG - Lock 140574853411984 acquired on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/44784bc58d4cb18d3549ad71e062efcf032d9ef5.lock\n",
      "2024-07-11 17:14:45,551 - DEBUG - https://huggingface.co:443 \"GET /microsoft/Florence-2-base-ft/resolve/main/tokenizer_config.json HTTP/11\" 200 34\n",
      "2024-07-11 17:14:45,554 - DEBUG - Attempting to release lock 140574853411984 on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/44784bc58d4cb18d3549ad71e062efcf032d9ef5.lock\n",
      "2024-07-11 17:14:45,554 - DEBUG - Lock 140574853411984 released on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/44784bc58d4cb18d3549ad71e062efcf032d9ef5.lock\n",
      "2024-07-11 17:14:45,612 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-base-ft/resolve/main/vocab.json HTTP/11\" 200 0\n",
      "2024-07-11 17:14:45,614 - DEBUG - Attempting to acquire lock 140574852834512 on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/94a2f4fd50e976bda926c700291522ea1a79323f.lock\n",
      "2024-07-11 17:14:45,615 - DEBUG - Lock 140574852834512 acquired on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/94a2f4fd50e976bda926c700291522ea1a79323f.lock\n",
      "2024-07-11 17:14:45,671 - DEBUG - https://huggingface.co:443 \"GET /microsoft/Florence-2-base-ft/resolve/main/vocab.json HTTP/11\" 200 1099884\n",
      "2024-07-11 17:14:45,735 - DEBUG - Attempting to release lock 140574852834512 on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/94a2f4fd50e976bda926c700291522ea1a79323f.lock\n",
      "2024-07-11 17:14:45,736 - DEBUG - Lock 140574852834512 released on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/94a2f4fd50e976bda926c700291522ea1a79323f.lock\n",
      "2024-07-11 17:14:45,790 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-base-ft/resolve/main/merges.txt HTTP/11\" 404 0\n",
      "2024-07-11 17:14:45,845 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-base-ft/resolve/main/tokenizer.json HTTP/11\" 200 0\n",
      "2024-07-11 17:14:45,847 - DEBUG - Attempting to acquire lock 140574659328336 on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/ad0bcbeb288f0d1373d88e0762e66357f55b8311.lock\n",
      "2024-07-11 17:14:45,848 - DEBUG - Lock 140574659328336 acquired on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/ad0bcbeb288f0d1373d88e0762e66357f55b8311.lock\n",
      "2024-07-11 17:14:45,898 - DEBUG - https://huggingface.co:443 \"GET /microsoft/Florence-2-base-ft/resolve/main/tokenizer.json HTTP/11\" 200 1355863\n",
      "2024-07-11 17:14:45,991 - DEBUG - Attempting to release lock 140574659328336 on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/ad0bcbeb288f0d1373d88e0762e66357f55b8311.lock\n",
      "2024-07-11 17:14:45,992 - DEBUG - Lock 140574659328336 released on /home/levlevi/.cache/huggingface/hub/.locks/models--microsoft--Florence-2-base-ft/ad0bcbeb288f0d1373d88e0762e66357f55b8311.lock\n",
      "2024-07-11 17:14:46,046 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-base-ft/resolve/main/added_tokens.json HTTP/11\" 404 0\n",
      "2024-07-11 17:14:46,152 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-base-ft/resolve/main/special_tokens_map.json HTTP/11\" 404 0\n",
      "2024-07-11 17:14:46,211 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-base-ft/resolve/main/configuration_florence2.py HTTP/11\" 200 0\n",
      "2024-07-11 17:14:46,415 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-base-ft/resolve/main/processor_config.json HTTP/11\" 404 0\n"
     ]
    }
   ],
   "source": [
    "model, processor = load_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use half precision\n",
    "half = model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_jersey_number(text):\n",
    "    # TODO: what about the number \"00\"?\n",
    "    if text.isdigit():\n",
    "        number = int(text)\n",
    "        return 0 <= number <= 99\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "\n",
    "BOOTSTRAPS = 1\n",
    "\n",
    "\n",
    "def preprocess_image(image, prompt, device):\n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].to(device, non_blocking=True)\n",
    "    pixel_values = inputs[\"pixel_values\"].to(device, non_blocking=True).half()\n",
    "    return input_ids, pixel_values\n",
    "\n",
    "def ocr(\n",
    "    image_file_paths: List[str],\n",
    "    model,\n",
    "    processor,\n",
    "    device: int = 0,\n",
    "    args: Optional[dict] = None,\n",
    ") -> Optional[List[str]]:\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    bootstraped_results = []\n",
    "\n",
    "    def load_image(fp):\n",
    "        try:\n",
    "            image = Image.open(fp)\n",
    "            image.load()\n",
    "            return image\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load image {fp}: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Load images in parallel\n",
    "    start = time.time()\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        images = list(executor.map(load_image, image_file_paths))\n",
    "    images = [img for img in images if img is not None]\n",
    "    end = time.time()\n",
    "    logger.debug(f\"Images loaded in: {end - start:.2f}s\")\n",
    "\n",
    "    if not images:\n",
    "        logger.error(\"No valid images loaded.\")\n",
    "        return None\n",
    "\n",
    "    # TODO: maybe resize images before using processor\n",
    "    prompts = [PROMPT] * len(images)\n",
    "    \n",
    "    start = time.time()\n",
    "    inputs = processor(text=prompts, images=images, return_tensors=\"pt\")\n",
    "    end = time.time()\n",
    "    logger.debug(f\"Preprocessing inputs took: {end - start:.2f}s\")\n",
    "\n",
    "    start = time.time()\n",
    "    input_ids = inputs[\"input_ids\"].to(device, non_blocking=True)\n",
    "    pixel_values = inputs[\"pixel_values\"].to(device, non_blocking=True).half()\n",
    "    end = time.time()\n",
    "    del inputs\n",
    "    logger.debug(f\"Copying + deleting inputs took: {end - start:.2f}s\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            pixel_values=pixel_values,\n",
    "            max_new_tokens=5,\n",
    "            do_sample=False,\n",
    "            early_stopping=False,\n",
    "            num_beams=BOOTSTRAPS,\n",
    "            num_return_sequences=BOOTSTRAPS,\n",
    "        )\n",
    "        end = time.time()\n",
    "        logger.debug(f\"Generating ids took: {end - start:.2f}s\")\n",
    "\n",
    "    # decode the generated text\n",
    "    start = time.time()\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    end = time.time()\n",
    "    logger.debug(f\"Batch decoding took: {end - start:.2f}s\")\n",
    "\n",
    "    # post-process the output\n",
    "    start = time.time()\n",
    "    for gt, image in zip(generated_text, images):\n",
    "        parsed_answer = processor.post_process_generation(\n",
    "            gt, task=\"<OCR>\", image_size=(image.width, image.height)\n",
    "        )\n",
    "        bootstraped_results.append(parsed_answer)\n",
    "    end = time.time()\n",
    "    logger.debug(f\"Post processing outputs took: {end - start:.2f}s\")\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     logger.error(f\"OCR processing failed: {e}\")\n",
    "    #     return None\n",
    "\n",
    "    return bootstraped_results if bootstraped_results else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 17:33:58,551 - DEBUG - Images loaded in: 0.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 17:34:00,645 - DEBUG - Preprocessing inputs took: 2.09s\n",
      "2024-07-11 17:34:00,747 - DEBUG - Copying + deleting inputs took: 0.06s\n",
      "2024-07-11 17:34:01,999 - DEBUG - Generating ids took: 1.25s\n",
      "2024-07-11 17:34:02,003 - DEBUG - Batch decoding took: 0.00s\n",
      "2024-07-11 17:34:02,004 - DEBUG - Post processing outputs took: 0.00s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total inference time: 3.5041072368621826s\n",
      "Inference time per prompt: 0.036501117050647736s\n",
      "[{'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}, {'<OCR>': '6'}]\n"
     ]
    }
   ],
   "source": [
    "ex_img_6 = \"/mnt/opr/levlevi/player-re-id/src/testing/constrastive_matching/clip_reid/data/data_reid/reid_challenge/gallery/00955.jpeg\"\n",
    "batch_size = 96\n",
    "\n",
    "start = time.time()\n",
    "results = ocr([ex_img_6] * batch_size, half, processor)\n",
    "end = time.time()\n",
    "print(f\"Total inference time: {end-start}s\")\n",
    "print(f\"Inference time per prompt: {(end-start) / batch_size}s\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Batch Size | Time/Image (Sec.) |\n",
    "| :---: | :---: |\n",
    "| 1 | 0.5399 | \n",
    "| 2 | 0.3558 |\n",
    "| 4 | 0.2159 |\n",
    "| **6** | **0.2114** |\n",
    "| 8 | OOM |\n",
    "\n",
    "--- \n",
    "\n",
    "| Batch Size | `.half()` | `autocast()` | Time/Image (Sec.) |\n",
    "| :---: | :---: |  :---: | :---: |\n",
    "| 4 | No | No | 0.2159 |\n",
    "| 4 | Yes | No | 0.0949 |\n",
    "| 8 | No | No | OOM |\n",
    "| 8 | Yes | No | 0.0856 |\n",
    "| 16 | Yes | No | 0.0808 |\n",
    "| 32 | Yes | No | 0.0785 |\n",
    "| 64 | Yes | No | 0.0783 |\n",
    "| 64 | Yes | Yes | 0.1006 |\n",
    "| **96** | **Yes** | No | **0.0778** |\n",
    "| 128 | Yes | No | OOM |\n",
    "\n",
    "---\n",
    "\n",
    "| `torch.backends.cuda.matmul.allow_tf32` | `torch.backends.cudnn.benchmark` | Time/Image (Sec.) |\n",
    "| :---: | :---: | :---: |\n",
    "| No | No | 0.0902 |\n",
    "| Yes | No | 0.0922 |\n",
    "| No | Yes | 0.0962 |\n",
    "| Yes | Yes | 0.0960 |\n",
    "\n",
    "---\n",
    "\n",
    "| Tokenizer | Time/Image (Sec.) |\n",
    "| :---: | :---: |\n",
    "| Default | **0.06187** | \n",
    "| `bart-base` | 0.06196 |\n",
    "\n",
    "---\n",
    "\n",
    "| Model Varient | Time/Image (Sec.) |\n",
    "| :---: | :---: |\n",
    "| `large-ft` | 0.06187 | \n",
    "| `base-ft` | **0.03936** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.397260273972606"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "1 / 0.03650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 17:11:12,128 - DEBUG - https://huggingface.co:443 \"HEAD /facebook/bart-base/resolve/main/tokenizer_config.json HTTP/11\" 404 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 17:11:12,176 - DEBUG - https://huggingface.co:443 \"HEAD /facebook/bart-base/resolve/main/vocab.json HTTP/11\" 200 0\n",
      "2024-07-11 17:11:12,343 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-large-ft/resolve/main/processor_config.json HTTP/11\" 404 0\n",
      "2024-07-11 17:11:12,397 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-large-ft/resolve/main/preprocessor_config.json HTTP/11\" 200 0\n",
      "2024-07-11 17:11:12,450 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-large-ft/resolve/main/preprocessor_config.json HTTP/11\" 200 0\n",
      "2024-07-11 17:11:12,500 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-large-ft/resolve/main/processing_florence2.py HTTP/11\" 200 0\n",
      "2024-07-11 17:11:12,569 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-large-ft/resolve/main/preprocessor_config.json HTTP/11\" 200 0\n",
      "2024-07-11 17:11:12,622 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-large-ft/resolve/main/tokenizer_config.json HTTP/11\" 200 0\n",
      "2024-07-11 17:11:12,671 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-large-ft/resolve/main/configuration_florence2.py HTTP/11\" 200 0\n",
      "2024-07-11 17:11:12,868 - DEBUG - https://huggingface.co:443 \"HEAD /microsoft/Florence-2-large-ft/resolve/main/processor_config.json HTTP/11\" 404 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer, BartTokenizerFast\n",
    "\n",
    "\n",
    "# tokenizer = BartTokenizerFast.from_pretrained(\"microsoft/Florence-2-large-ft\")\n",
    "tok = BartTokenizerFast.from_pretrained(\"facebook/bart-base\")\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    \"microsoft/Florence-2-large-ft\",\n",
    "    trust_remote_code=True,\n",
    "    # tokenizer=tok,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
