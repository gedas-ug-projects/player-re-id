{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/embedding.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m HUMAN_LABELS_FP \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/path/to/human_labels.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     66\u001b[0m GROUND_TRUTH_FP \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/path/to/ground_truth.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 68\u001b[0m all_tracklet_features, human_labels, ground_truth_player_features_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEMBEDDING_FP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHUMAN_LABELS_FP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGROUND_TRUTH_FP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Convert ground truth dictionary to dataframe\u001b[39;00m\n\u001b[1;32m     71\u001b[0m ground_truth_player_features_list \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(embedding_fp, human_labels_fp, ground_truth_fp)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(embedding_fp: \u001b[38;5;28mstr\u001b[39m, human_labels_fp: \u001b[38;5;28mstr\u001b[39m, ground_truth_fp: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 14\u001b[0m     all_tracklet_features \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_fp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     human_labels \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(human_labels_fp)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(ground_truth_fp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/pickle.py:179\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    178\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/embedding.pkl'"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from scipy.spatial.distance import cdist\n",
    "import json\n",
    "from collections import Counter\n",
    "from difflib import SequenceMatcher\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Load Data\n",
    "def load_data(embedding_fp: str, human_labels_fp: str, ground_truth_fp: str):\n",
    "    all_tracklet_features = pd.read_pickle(embedding_fp)\n",
    "    human_labels = pd.read_csv(human_labels_fp)\n",
    "    with open(ground_truth_fp, 'r') as f:\n",
    "        ground_truth_player_features_dict = json.load(f)\n",
    "    return all_tracklet_features, human_labels, ground_truth_player_features_dict\n",
    "\n",
    "# Generate Feature Vector\n",
    "def generate_feature_vector(\n",
    "    all_tracklet_features: pd.DataFrame,\n",
    "    ground_truth_player_features_subset_df: pd.DataFrame,\n",
    "    human_labels: List[float]\n",
    ") -> List[float]:\n",
    "    reidentified_tracklet_player_ids = [np.nan] * len(human_labels)\n",
    "    ground_truth_embeddings = np.vstack(ground_truth_player_features_subset_df['embedding'].values)\n",
    "    ground_truth_player_ids = ground_truth_player_features_subset_df['player_id'].values\n",
    "    \n",
    "    for tracklet_index, tracklet_row in enumerate(all_tracklet_features.itertuples()):\n",
    "        tracklet_embedding = np.array(tracklet_row.embedding).reshape(1, -1)\n",
    "        distances = cdist(tracklet_embedding, ground_truth_embeddings, metric='euclidean')\n",
    "        best_match_idx = np.argmin(distances)\n",
    "        best_match_player_id = ground_truth_player_ids[best_match_idx]\n",
    "        reidentified_tracklet_player_ids[tracklet_index] = best_match_player_id\n",
    "    \n",
    "    return reidentified_tracklet_player_ids\n",
    "\n",
    "# Utility Functions for Majority Voting\n",
    "def get_majority_element(elements: List[str]) -> str:\n",
    "    if not elements:\n",
    "        return None\n",
    "    counter = Counter(elements)\n",
    "    return counter.most_common(1)[0][0]\n",
    "\n",
    "# Calculate String Similarity\n",
    "def calculate_string_similarity_score(string_one: str, string_two: str) -> float:\n",
    "    return SequenceMatcher(None, string_one, string_two).ratio()\n",
    "\n",
    "def find_closest_player_id(player_name: str, ground_truth_dict: dict) -> str:\n",
    "    best_similarity = -1\n",
    "    best_player_id_match = None\n",
    "    for team in ground_truth_dict:\n",
    "        for player in ground_truth_dict[team]['players']:\n",
    "            cand_full_name = ' '.join(player.split(',')[::-1]) if ',' in player else player\n",
    "            player_id = ground_truth_dict[team]['players'][player]['player_id']\n",
    "            similarity = calculate_string_similarity_score(player_name, cand_full_name)\n",
    "            if similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_player_id_match = player_id\n",
    "    return best_player_id_match\n",
    "\n",
    "EMBEDDING_FP = '/path/to/embedding.pkl'\n",
    "HUMAN_LABELS_FP = '/path/to/human_labels.csv'\n",
    "GROUND_TRUTH_FP = '/path/to/ground_truth.json'\n",
    "\n",
    "all_tracklet_features, human_labels, ground_truth_player_features_dict = load_data(EMBEDDING_FP, HUMAN_LABELS_FP, GROUND_TRUTH_FP)\n",
    "\n",
    "# Convert ground truth dictionary to dataframe\n",
    "ground_truth_player_features_list = []\n",
    "for team in ground_truth_player_features_dict:\n",
    "    for player in ground_truth_player_features_dict[team]['players']:\n",
    "        player_data = ground_truth_player_features_dict[team]['players'][player]\n",
    "        player_data['player_id'] = player\n",
    "        ground_truth_player_features_list.append(player_data)\n",
    "ground_truth_player_features_subset_df = pd.DataFrame(ground_truth_player_features_list)\n",
    "\n",
    "# Generate feature vector\n",
    "reidentified_tracklet_player_ids = generate_feature_vector(all_tracklet_features, ground_truth_player_features_subset_df, human_labels)\n",
    "\n",
    "# Prepare final DataFrame\n",
    "predictions_computed = pd.DataFrame({'tracklet_file_path': all_tracklet_features['tracklet_file_path'], 'human_label': human_labels, 'prediction': reidentified_tracklet_player_ids})\n",
    "print(predictions_computed.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
