{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# q: how can we represent players as feature vectors?\n",
    "raw_features_fp = '/playpen-storage/levlevi/player-re-id/src/data/raw_features.json'\n",
    "raw_features_df_fp = '/playpen-storage/levlevi/player-re-id/src/data/team_rosters_df.csv'\n",
    "with open(raw_features_fp, 'r') as f:\n",
    "    raw_features = json.load(f)\n",
    "raw_features_df = pd.read_csv(raw_features_df_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which features are redundant?\n",
    "df_redundant_features_dropped = raw_features_df[['team_id', 'player_id', 'jersey_number']]\n",
    "\n",
    "# did a player play in this game-period?\n",
    "# encode each player's player_id using a one hot encoding\n",
    "df_redundant_features_dropped['player_id_one_hot'] = df_redundant_features_dropped['player_id']\n",
    "\n",
    "# which features can be one-hot encoded?\n",
    "df_one_hot_team_id = pd.get_dummies(df_redundant_features_dropped, columns=['team_id', 'player_id_one_hot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert each player has exactly one one-hot encoding\n",
    "for row, player_id in zip(df_one_hot_team_id.iloc[:, 32: ].itertuples(), df_one_hot_team_id['player_id']):\n",
    "    for val, header in zip(row[1: ], df_one_hot_team_id.iloc[:, 32: ]):\n",
    "        player_id_str = header.split('_')[-1]\n",
    "        if int(player_id_str) == int(player_id):\n",
    "            assert int(val) == 1\n",
    "        else:\n",
    "            assert int(val) == 0, f\"player_id: {player_id}, val: {val}, header: {header}\"\n",
    "    assert sum([int(x) for x in row[1: ]]) == 1\n",
    "assert len(df_one_hot_team_id.iloc[:, 32: ]) == len(raw_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Ground-Truth Features to Embeddings (1x45)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import FastText\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "JERSEY_VECTOR_SIZE = 30\n",
    "df = df_one_hot_team_id.copy()\n",
    "\n",
    "# prepare data for FastText embedding\n",
    "jersey_numbers = df['jersey_number'].astype(str).tolist()\n",
    "\n",
    "sentences = [[char for char in number] for number in jersey_numbers]\n",
    "# train a FastText model\n",
    "model = FastText(sentences, vector_size=JERSEY_VECTOR_SIZE, window=1, min_count=1, sg=1)\n",
    "\n",
    "# get embeddings for jersey numbers\n",
    "def get_embedding(number):\n",
    "    return model.wv[number]\n",
    "df['jersey_embedding'] = df['jersey_number'].apply(lambda x: get_embedding(x))\n",
    "# expand the embeddings into separate columns\n",
    "embeddings = pd.DataFrame(df['jersey_embedding'].tolist(), index=df.index)\n",
    "\n",
    "# add jersey embeddings\n",
    "df = df.drop(columns=['jersey_embedding', 'jersey_number']).join(embeddings)\n",
    "\n",
    "# boolean columns\n",
    "bool_columns = df.select_dtypes(include='bool').columns\n",
    "df[bool_columns] = df[bool_columns].astype(int)\n",
    "# convert all columns to float\n",
    "df = df.astype(float)\n",
    "\n",
    "# select feature columns\n",
    "feature_columns = [col for col in df.columns if col != 'player_id']\n",
    "X = df[feature_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert each player has exactly one one-hot encoding\n",
    "\n",
    "for row, player_id in zip(X.iloc[:, 30: -30].itertuples(), df_one_hot_team_id['player_id']):\n",
    "    for val, header in zip(row[1: ], X.iloc[:, 30: -30]):\n",
    "        player_id_str = header.split('_')[-1]\n",
    "        if int(player_id_str) == int(player_id):\n",
    "            assert int(val) == 1\n",
    "        else:\n",
    "            assert int(val) == 0, f\"player_id: {player_id}, val: {val}, header: {header}\"\n",
    "    assert sum([int(x) for x in row[1: ]]) == 1\n",
    "    \n",
    "assert len(X.iloc[:, 30: -30].columns) == len(raw_features_df['player_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = len(X.columns)\n",
    "# remove column names\n",
    "X_no_columns = X.copy()\n",
    "X_no_columns.columns = np.arange(num_cols)\n",
    "\n",
    "# normalize all features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X_no_columns)\n",
    "\n",
    "# target column (labels)\n",
    "y = df['player_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Predictions to Embeddings\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# how can we convert model predictions to feature vectors?\n",
    "# human labels for 50 tracklet test set\n",
    "with open('/playpen-storage/levlevi/player-re-id/src/data/_50_game_reid_benchmark_/annotations.json') as f:\n",
    "    annotations = json.load(f)\n",
    "    \n",
    "# convert raw florence preditions to dict\n",
    "florence_predictions_fp = '/playpen-storage/levlevi/player-re-id/src/data/florence_100_track_bm_results.json'\n",
    "def read_florence_predictions(fp):\n",
    "    with open(fp, 'r') as f:\n",
    "        florence_predictions = f.readlines()\n",
    "    predictions = {}\n",
    "    for p in florence_predictions:\n",
    "        key = p.split(':')[0]\n",
    "        values = ast.literal_eval('{' + '{'.join(p.split('{')[1: ]))\n",
    "        predictions[key] = values\n",
    "    return predictions\n",
    "predictions = read_florence_predictions(florence_predictions_fp)\n",
    "\n",
    "# roster metadata\n",
    "with open(\"/playpen-storage/levlevi/player-re-id/src/data/raw_features.json\", 'r') as f:\n",
    "    rosters = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from collections import Counter\n",
    "\n",
    "# get most common race from list\n",
    "def get_maj_race(races):\n",
    "    if len(races) == 0:\n",
    "        return None\n",
    "    counter = Counter(races)\n",
    "    return counter.most_common(1)[0][0]\n",
    "\n",
    "# get most common player postion from list\n",
    "def get_maj_position(positions):\n",
    "    if len(positions) == 0:\n",
    "        return None\n",
    "    counter = Counter(positions)\n",
    "    return counter.most_common(1)[0][0]\n",
    "\n",
    "# get most common jersey number from list\n",
    "def get_maj_jersey_number(jersey_numbers):\n",
    "    if len(jersey_numbers) == 0:\n",
    "        return None\n",
    "    counter = Counter(jersey_numbers)\n",
    "    return counter.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "HUDL_GAME_LOGS_DIR = '/mnt/sun/levlevi/nba-plus-statvu-dataset/hudl-game-logs'\n",
    "# id: fp\n",
    "game_logs_map = {\n",
    "    f.split('.')[-2]: os.path.join(HUDL_GAME_LOGS_DIR, f) for f in os.listdir(HUDL_GAME_LOGS_DIR)\n",
    "}\n",
    "\n",
    "def calculate_string_similarity_score(string_one, string_two):\n",
    "    return SequenceMatcher(None, string_one, string_two).ratio()\n",
    "\n",
    "def find_closest_player_id(player_name: str) -> str:\n",
    "    best_similarity = -100\n",
    "    best_player_id_match = None\n",
    "    best_match_name = ''\n",
    "    for team in raw_features:\n",
    "        for player in raw_features[team]['players']:\n",
    "            cand_full_name = ''\n",
    "            if ',' not in player:\n",
    "                cand_full_name = player\n",
    "            else:\n",
    "                cand_full_name = player.split(',')[1] + ' ' + player.split(',')[0]\n",
    "            player_id = raw_features[team]['players'][player]['player_id']\n",
    "            similarity = calculate_string_similarity_score(cand_full_name, player_name)\n",
    "            if similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_player_id_match = player_id\n",
    "                best_match_name = cand_full_name\n",
    "    # sanity check\n",
    "    # print(player_name, best_match_name, best_similarity)\n",
    "    return int(best_player_id_match)\n",
    "\n",
    "def get_candidate_player_ids(tracklet_fp: str) -> List[str]:\n",
    "    game_id = tracklet_fp.split('/')[-2].split('_')[0]\n",
    "    period = tracklet_fp.split('/')[-2].split('_')[-1].split('period')[1][0]\n",
    "    period = int(period)\n",
    "    df = pd.read_csv(game_logs_map[game_id], delimiter=';')\n",
    "    df['is_period'] = df['half'].apply(lambda x: x == period)\n",
    "    df_period_matched = df[df['is_period'] == True]\n",
    "    \n",
    "    unique_player_ids = set()\n",
    "    unique_player_names = set(df['player_name'].unique())\n",
    "    unique_player_names = set(df_period_matched['player_name'].unique())\n",
    "    unique_player_names_no_nan = {p for p in unique_player_names if not pd.isna(p)}\n",
    "    for pn in unique_player_names_no_nan:\n",
    "        unique_player_ids.add(find_closest_player_id(pn))\n",
    "    return unique_player_ids\n",
    "\n",
    "def get_candidate_team_ids(tracklet_fp: str):\n",
    "    team_one_name = tracklet_fp.split('/')[-2].split('_')[3].replace(\" \", \"_\")\n",
    "    team_two_name = tracklet_fp.split('/')[-2].split('_')[5].replace(\" \", \"_\")\n",
    "    team_one_id = rosters[team_one_name]['team_id']\n",
    "    team_two_id = rosters[team_two_name]['team_id']\n",
    "    return [team_one_id, team_two_id]\n",
    "\n",
    "# create dataframe for all tracklet predictions\n",
    "predictions_df = pd.DataFrame()\n",
    "# all rows in predictions df\n",
    "rows = []\n",
    "for tracklet_fp, raw_predictions in predictions.items():\n",
    "    # get team ids from file path\n",
    "    predicted_jersey_numbers = []\n",
    "    candidate_team_ids = get_candidate_team_ids(tracklet_fp)\n",
    "    candidate_players_ids = get_candidate_player_ids(tracklet_fp)\n",
    "    # get jersey numbers\n",
    "    for frame_idx in raw_predictions:\n",
    "        # match all valid predictions\n",
    "        temp_jersey_number_arr = re.findall(r'\\d+', raw_predictions[frame_idx].get('<OCR>'))\n",
    "        for n in temp_jersey_number_arr:\n",
    "            predicted_jersey_numbers.append(n)\n",
    "    # find most common jersey number\n",
    "    maj_jersey_number = get_maj_jersey_number(predicted_jersey_numbers)\n",
    "    temp_row = [tracklet_fp, maj_jersey_number, candidate_team_ids, candidate_players_ids]\n",
    "    rows.append(temp_row)\n",
    "    \n",
    "# add all rows to df\n",
    "predictions_df = pd.DataFrame(rows, columns=['tracklet_file_path', 'jersey_number', 'candidate_team_ids', 'candidate_player_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1718 player_id_one_hot_1718\n",
      "0.0\n",
      "-0.04708816093480111\n",
      "2037 player_id_one_hot_2037\n",
      "0.0\n",
      "-0.04708816093480111\n",
      "2746 player_id_one_hot_2746\n",
      "0.0\n",
      "-0.0470881609348011\n",
      "101108 player_id_one_hot_101108\n",
      "0.0\n",
      "-0.04708816093480111\n",
      "200755 player_id_one_hot_200755\n",
      "0.0\n",
      "-0.04708816093480111\n",
      "201564 player_id_one_hot_201564\n",
      "0.0\n",
      "-0.0470881609348011\n",
      "201599 player_id_one_hot_201599\n",
      "0.0\n",
      "-0.04708816093480111\n",
      "201601 player_id_one_hot_201601\n",
      "0.0\n",
      "-0.04708816093480111\n",
      "201933 player_id_one_hot_201933\n",
      "0.0\n",
      "-0.04708816093480111\n",
      "202325 player_id_one_hot_202325\n",
      "0.0\n",
      "-0.04708816093480111\n",
      "202328 player_id_one_hot_202328\n",
      "0.0\n",
      "-0.0470881609348011\n",
      "202362 player_id_one_hot_202362\n",
      "0.0\n",
      "-0.0470881609348011\n",
      "203085 player_id_one_hot_203085\n",
      "0.0\n",
      "-0.04708816093480111\n",
      "203089 player_id_one_hot_203089\n",
      "0.0\n",
      "-0.06666666666666667\n",
      "203114 player_id_one_hot_203114\n",
      "0.0\n",
      "-0.0470881609348011\n",
      "203487 player_id_one_hot_203487\n",
      "0.0\n",
      "-0.06666666666666667\n",
      "203507 player_id_one_hot_203507\n",
      "0.0\n",
      "-0.0470881609348011\n",
      "203948 player_id_one_hot_203948\n",
      "0.0\n",
      "-0.0470881609348011\n",
      "203953 player_id_one_hot_203953\n",
      "0.0\n",
      "-0.0470881609348011\n",
      "1626173 player_id_one_hot_1626173\n",
      "0.0\n",
      "-0.0470881609348011\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[409], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28mprint\u001b[39m(X_scaled[\u001b[38;5;241m0\u001b[39m][row_idx\u001b[38;5;241m+\u001b[39mindex])\n\u001b[1;32m     54\u001b[0m         blank_feature[row_idx \u001b[38;5;241m+\u001b[39m index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     58\u001b[0m index \u001b[38;5;241m=\u001b[39m PLAYER_IDS_END_IDX\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# get player jersey number\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "import sys\n",
    "\n",
    "# features: team_ids, player_ids, jersey_numbers, \n",
    "TEAM_COL_START_IDX = 0\n",
    "TEAM_COL_END_IDX = JERSEY_VECTOR_SIZE\n",
    "# TEAM_COL_END_IDX = 30\n",
    "\n",
    "# PLAYER_IDS_START_IDX = 30\n",
    "PLAYER_IDS_START_IDX = TEAM_COL_END_IDX\n",
    "PLAYER_IDS_END_IDX = PLAYER_IDS_START_IDX + (len(X.columns) - TEAM_COL_END_IDX - JERSEY_VECTOR_SIZE)\n",
    "\n",
    "JERSEY_NUM_START_IDX = PLAYER_IDS_END_IDX\n",
    "\n",
    "# all prediction embeddings\n",
    "all_prediction_embeddings = []\n",
    "\n",
    "# team_ids column names\n",
    "team_ids_column_names = list(X.columns)[TEAM_COL_START_IDX:TEAM_COL_END_IDX]\n",
    "\n",
    "# player_ids column names\n",
    "player_ids_column_names = list(X.columns)[PLAYER_IDS_START_IDX:PLAYER_IDS_END_IDX]\n",
    "\n",
    "# jersey_number column names\n",
    "jersey_column_names = list(X.columns)[JERSEY_NUM_START_IDX: ]\n",
    "\n",
    "# tracklet file paths\n",
    "tracklet_file_paths = list(predictions_df['tracklet_file_path'])\n",
    "\n",
    "for idx, player_features in predictions_df.iterrows():\n",
    "    # blank feature vector\n",
    "    blank_feature = np.zeros(len(X.columns))\n",
    "    # feature vector index place holder\n",
    "    index = 0\n",
    "        \n",
    "    # set one-hot encoded team ids indices to 1\n",
    "    potential_team_ids = set(player_features['candidate_team_ids'])\n",
    "    \n",
    "    for row_idx, team_str in enumerate(team_ids_column_names):\n",
    "        team_id = int(team_str.split('_')[-1])\n",
    "        if team_id in potential_team_ids:\n",
    "            blank_feature[row_idx] = 1\n",
    "        index += 1\n",
    "        \n",
    "    # encode candidate player ids\n",
    "    # set one-hot encoded player ids indices to 1\n",
    "    potential_player_ids = set(player_features['candidate_player_ids'])\n",
    "    for row_idx, player_str in enumerate(player_ids_column_names):\n",
    "        player_id = int(player_str.split('_')[-1])\n",
    "        if player_id in potential_player_ids:\n",
    "            print(player_id, X.columns[row_idx + index])\n",
    "            print(X.iloc[0, row_idx+index])\n",
    "            print(X_scaled[0][row_idx+index])\n",
    "            blank_feature[row_idx + index] = 1\n",
    "        \n",
    "    assert False\n",
    "\n",
    "    index = PLAYER_IDS_END_IDX\n",
    "    \n",
    "    # get player jersey number\n",
    "    predicted_jersey_number = player_features['jersey_number']\n",
    "    if not predicted_jersey_number:\n",
    "        predicted_jersey_number = -sys.maxsize + 1\n",
    "    # generate embedding\n",
    "    jersey_number_encoding = get_embedding(predicted_jersey_number)\n",
    "    for row_idx, val in enumerate(jersey_number_encoding):\n",
    "        blank_feature[row_idx + index] = val\n",
    "    \n",
    "    # add feature vector to list\n",
    "    all_prediction_embeddings.append(blank_feature)\n",
    "\n",
    "# convert to array\n",
    "all_prediction_embeddings = np.array(all_prediction_embeddings)\n",
    "\n",
    "# scale features\n",
    "scaler = StandardScaler()\n",
    "all_prediction_embeddings_scaled = scaler.fit_transform(all_prediction_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euclidean Distance\n",
    "def euclidean_distance(vec1: List[float], vec2: List[float]) -> float:\n",
    "    return math.sqrt(sum((x - y) ** 2 for x, y in zip(vec1, vec2)))\n",
    "\n",
    "# cosine Similarity\n",
    "def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:\n",
    "    dot_product = sum(x * y for x, y in zip(vec1, vec2))\n",
    "    magnitude1 = math.sqrt(sum(x ** 2 for x in vec1))\n",
    "    magnitude2 = math.sqrt(sum(y ** 2 for y in vec2))\n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        return 0.0  # Avoid division by zero\n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "def pearson_correlation(vec1: List[float], vec2: List[float]) -> float:\n",
    "    n = len(vec1)\n",
    "    sum1 = sum(vec1)\n",
    "    sum2 = sum(vec2)\n",
    "    sum1_sq = sum(x ** 2 for x in vec1)\n",
    "    sum2_sq = sum(y ** 2 for y in vec2)\n",
    "    product_sum = sum(x * y for x, y in zip(vec1, vec2))\n",
    "    \n",
    "    numerator = product_sum - (sum1 * sum2 / n)\n",
    "    denominator = math.sqrt((sum1_sq - sum1 ** 2 / n) * (sum2_sq - sum2 ** 2 / n))\n",
    "    if denominator == 0:\n",
    "        return 0.0  # Avoid division by zero\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY USE TEAM AND JERSEY NUMBER EMBEDDINGS\n",
    "# all_prediction_embeddings_scaled = scaler.fit_transform([np.concatenate([x[TEAM_COL_START_IDX: TEAM_COL_END_IDX], x[JERSEY_NUM_START_IDX: ]]) for x in all_prediction_embeddings_scaled])\n",
    "# X_scaled = scaler.fit_transform([np.concatenate([x[TEAM_COL_START_IDX: TEAM_COL_END_IDX], x[JERSEY_NUM_START_IDX: ]]) for x in X_scaled])\n",
    "\n",
    "player_ids_gt = y.copy()\n",
    "human_labels = []\n",
    "\n",
    "for fp in tracklet_file_paths:\n",
    "    video_name = fp.split('/')[-2]\n",
    "    subtrack = fp.split('/')[-1]\n",
    "    human_label = annotations[video_name]['tracks'][subtrack]['human_annotation']\n",
    "    human_labels.append(human_label)\n",
    "    \n",
    "predictions_from_features = [np.nan] * len(human_labels)\n",
    "for pred_fv_idx, feature_vector in enumerate(all_prediction_embeddings_scaled):\n",
    "    best_score = sys.maxsize - 1\n",
    "    best_match_idx = np.nan \n",
    "    for gt_fv_idx, gt_feature_vector in enumerate(X_scaled):\n",
    "        euclidean_dist = euclidean_distance(feature_vector, gt_feature_vector)\n",
    "        gt_feature_vector[PLAYER_IDS_START_IDX: PLAYER_IDS_END_IDX] = 0\n",
    "        if euclidean_dist < best_score:\n",
    "            best_score = euclidean_dist\n",
    "            best_match_idx = gt_fv_idx\n",
    "            \n",
    "    predictions_from_features[pred_fv_idx] = player_ids_gt[best_match_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with all predictions\n",
    "predictions_computed = pd.DataFrame({'tracklet_file_path': tracklet_file_paths, 'human_label': human_labels, 'prediction': predictions_from_features})\n",
    "predictions_computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all matching predictions\n",
    "matched_mask = predictions_computed['human_label'] == predictions_computed['prediction']\n",
    "predictions_computed_matched = predictions_computed[matched_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all ids to floats\n",
    "predictions_computed_no_na = predictions_computed_matched.dropna()\n",
    "predictions_computed_no_na['human_label'] = predictions_computed_no_na['human_label'].astype(int)\n",
    "predictions_computed_no_na['prediction'] = predictions_computed_no_na['prediction'].astype(int)\n",
    "\n",
    "# find all matching predictions\n",
    "matched_mask = abs(predictions_computed_no_na['human_label'] - predictions_computed_no_na['prediction']) < 0.5\n",
    "predictions_no_na_matched = predictions_computed_no_na[matched_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions_no_na_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1, 0, 0, 0, 1, 0, 1]).astype(np.float32)\n",
    "v2 = np.array([0, 1, 0, 1, 0, 1, 0]).astype(np.float32)\n",
    "v3 = np.array([0, 0, 1, 0, 1, 1, 0]).astype(np.float32)\n",
    "c1 = np.array([1, 1, 0, 1, 1, 0, 1]).astype(np.float32)\n",
    "\n",
    "print(euclidean_distance(c1, v1), euclidean_distance(c1, v2), euclidean_distance(c1, v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
