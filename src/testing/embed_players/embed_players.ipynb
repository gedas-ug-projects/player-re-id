{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: how can we represent players as feature vectors?\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "raw_features_fp = '/playpen-storage/levlevi/player-re-id/src/data/raw_features.json'\n",
    "raw_features_df_fp = '/playpen-storage/levlevi/player-re-id/src/data/team_rosters_df.csv'\n",
    "with open(raw_features_fp, 'r') as f:\n",
    "    raw_features = json.load(f)\n",
    "raw_features_df = pd.read_csv(raw_features_df_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which features are redundant?\n",
    "df_redundant_features_dropped = raw_features_df[['team_id', 'player_id', 'team_colors', 'position', 'jersey_number', 'race']]\n",
    "# which features can be one-hot encoded?\n",
    "df_one_hot_team_id = pd.get_dummies(df_redundant_features_dropped, columns=['team_id', 'race',])\n",
    "# segment positions (i.e. multi-category)\n",
    "positions_segmented = []\n",
    "for pos in df_one_hot_team_id['position']:\n",
    "    if len(pos) == 2:\n",
    "        positions_segmented.append([pos])\n",
    "    else:\n",
    "        positions_segmented.append(pos.split('/'))\n",
    "df_positions_segmented = df_one_hot_team_id.copy()         \n",
    "df_positions_segmented['position'] = positions_segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how do we encode positions\n",
    "unique_positions = set(pos for sublist in df_positions_segmented['position'] for pos in sublist)\n",
    "# create columns for each unique position\n",
    "for pos in unique_positions:\n",
    "    df_positions_segmented[f'position_{pos}'] = df_positions_segmented['position'].apply(lambda x: 1 if pos in x else 0)\n",
    "# drop the original position column\n",
    "df_positions_segmented.drop('position', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop team colors for now\n",
    "df_no_team_colors = df_positions_segmented.copy()\n",
    "df_no_team_colors.drop('team_colors', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Ground-Truth Features to Embeddings (1x45)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import FastText\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = df_no_team_colors.copy()\n",
    "# prepare data for FastText embedding\n",
    "jersey_numbers = df['jersey_number'].astype(str).tolist()\n",
    "sentences = [[char for char in number] for number in jersey_numbers]\n",
    "# train a FastText model\n",
    "model = FastText(sentences, vector_size=10, window=3, min_count=1, sg=1)\n",
    "# get embeddings for jersey numbers\n",
    "def get_embedding(number):\n",
    "    return model.wv[number]\n",
    "df['jersey_embedding'] = df['jersey_number'].apply(lambda x: get_embedding(x))\n",
    "# expand the embeddings into separate columns\n",
    "embeddings = pd.DataFrame(df['jersey_embedding'].tolist(), index=df.index)\n",
    "df = df.drop(columns=['jersey_embedding', 'jersey_number']).join(embeddings)\n",
    "# boolean columns\n",
    "bool_columns = df.select_dtypes(include='bool').columns\n",
    "df[bool_columns] = df[bool_columns].astype(int)\n",
    "# convert all columns to float\n",
    "df = df.astype(float)\n",
    "# feature columns\n",
    "feature_columns = [col for col in df.columns if col != 'player_id']\n",
    "X = df[feature_columns]\n",
    "num_cols = len(X.columns)\n",
    "X.columns = np.arange(num_cols)\n",
    "# scale all features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# target column (labels)\n",
    "y = df['player_id']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Predictions to Embeddings\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how can we convert model predictions to feature vectors?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
