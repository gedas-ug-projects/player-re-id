{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from typing import List\n",
    "from scipy.spatial.distance import cdist\n",
    "from gensim.models import FastText, Word2Vec\n",
    "from typing import List\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Read Player Feature Data**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_player_features_fp = '/playpen-storage/levlevi/player-re-id/src/data/raw_features.json'\n",
    "ground_truth_player_features_df_fp = '/playpen-storage/levlevi/player-re-id/src/data/team_rosters_df.csv'\n",
    "with open(ground_truth_player_features_fp, 'r') as f:\n",
    "    ground_truth_player_features_dict = json.load(f)\n",
    "ground_truth_player_features_df = pd.read_csv(ground_truth_player_features_df_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which features are redundant?\n",
    "ground_truth_player_features_subset_df = ground_truth_player_features_df[['team_id', 'player_id', 'jersey_number']]\n",
    "\n",
    "# add feature to indicate if player is in game\n",
    "ground_truth_player_features_subset_df['player_in_game'] = [False] * len(ground_truth_player_features_subset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Format Tracklet Predicted Features**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# human labels for 50 tracklet test set\n",
    "with open('/playpen-storage/levlevi/player-re-id/src/data/_50_game_reid_benchmark_/annotations.json') as f:\n",
    "    tracklet_human_annotations_dict = json.load(f)\n",
    "    \n",
    "# convert raw florence preditions to dict\n",
    "florence_predictions_fp = '/playpen-storage/levlevi/player-re-id/src/data/florence_100_track_bm_results.json'\n",
    "def read_florence_predictions(fp):\n",
    "    with open(fp, 'r') as f:\n",
    "        florence_predictions = f.readlines()\n",
    "    predictions = {}\n",
    "    for p in florence_predictions:\n",
    "        key = p.split(':')[0]\n",
    "        values = ast.literal_eval('{' + '{'.join(p.split('{')[1: ]))\n",
    "        predictions[key] = values\n",
    "    return predictions\n",
    "predicted_tracklet_features_florence_dict = read_florence_predictions(florence_predictions_fp)\n",
    "\n",
    "# roster metadata\n",
    "with open(\"/playpen-storage/levlevi/player-re-id/src/data/raw_features.json\", 'r') as f:\n",
    "    ground_truth_player_features_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get most common race from list\n",
    "def get_maj_race(races):\n",
    "    if len(races) == 0:\n",
    "        return None\n",
    "    counter = Counter(races)\n",
    "    return counter.most_common(1)[0][0]\n",
    "\n",
    "# get most common player postion from list\n",
    "def get_maj_position(positions):\n",
    "    if len(positions) == 0:\n",
    "        return None\n",
    "    counter = Counter(positions)\n",
    "    return counter.most_common(1)[0][0]\n",
    "\n",
    "# get most common jersey number from list\n",
    "def get_maj_jersey_number(jersey_numbers):\n",
    "    if len(jersey_numbers) == 0:\n",
    "        return None\n",
    "    counter = Counter(jersey_numbers)\n",
    "    return counter.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUDL_GAME_LOGS_DIR = '/mnt/sun/levlevi/nba-plus-statvu-dataset/hudl-game-logs'\n",
    "# id: fp\n",
    "game_logs_map = {\n",
    "    f.split('.')[-2]: os.path.join(HUDL_GAME_LOGS_DIR, f) for f in os.listdir(HUDL_GAME_LOGS_DIR)\n",
    "}\n",
    "\n",
    "def calculate_string_similarity_score(string_one, string_two):\n",
    "    return SequenceMatcher(None, string_one, string_two).ratio()\n",
    "\n",
    "def find_closest_player_id(player_name: str) -> int:\n",
    "    best_similarity = -float('inf')\n",
    "    best_player_id_match = None\n",
    "    for _, team_data in ground_truth_player_features_dict.items():\n",
    "        for player, player_data in team_data['players'].items():\n",
    "            # convert player name to full name\n",
    "            full_name = player if ',' not in player else ' '.join(reversed(player.split(',')))\n",
    "            player_id = player_data['player_id']\n",
    "            similarity = calculate_string_similarity_score(full_name, player_name)\n",
    "            if similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_player_id_match = player_id\n",
    "    if best_player_id_match is None:\n",
    "        raise ValueError(f\"No matching player found for the name: {player_name}\")\n",
    "    return int(best_player_id_match)\n",
    "\n",
    "def get_candidate_player_ids(tracklet_fp: str) -> List[str]:\n",
    "    game_id = tracklet_fp.split('/')[-2].split('_')[0]\n",
    "    period = tracklet_fp.split('/')[-2].split('_')[-1].split('period')[1][0]\n",
    "    period = int(period)\n",
    "    df = pd.read_csv(game_logs_map[game_id], delimiter=';')\n",
    "    df['is_period'] = df['half'].apply(lambda x: x == period)\n",
    "    df_period_matched = df[df['is_period'] == True]\n",
    "    \n",
    "    unique_player_ids = set()\n",
    "    unique_player_names = set(df['player_name'].unique())\n",
    "    unique_player_names = set(df_period_matched['player_name'].unique())\n",
    "    unique_player_names_no_nan = {p for p in unique_player_names if not pd.isna(p)}\n",
    "    for pn in unique_player_names_no_nan:\n",
    "        unique_player_ids.add(find_closest_player_id(pn))\n",
    "    return unique_player_ids\n",
    "\n",
    "def get_candidate_team_ids(tracklet_fp: str) -> List[str]:\n",
    "    team_one_name = tracklet_fp.split('/')[-2].split('_')[3].replace(\" \", \"_\")\n",
    "    team_two_name = tracklet_fp.split('/')[-2].split('_')[5].replace(\" \", \"_\")\n",
    "    team_one_id = ground_truth_player_features_dict[team_one_name]['team_id']\n",
    "    team_two_id = ground_truth_player_features_dict[team_two_name]['team_id']\n",
    "    return [team_one_id, team_two_id]\n",
    "\n",
    "# all rows in predictions df\n",
    "rows = []\n",
    "for tracklet_fp, raw_predictions in predicted_tracklet_features_florence_dict.items():\n",
    "    # get team ids from file path\n",
    "    predicted_jersey_numbers = []\n",
    "    candidate_team_ids = get_candidate_team_ids(tracklet_fp)\n",
    "    candidate_players_ids = get_candidate_player_ids(tracklet_fp)\n",
    "    # get jersey numbers\n",
    "    for frame_idx in raw_predictions:\n",
    "        # match all valid predictions\n",
    "        temp_jersey_number_arr = re.findall(r'\\d+', raw_predictions[frame_idx].get('<OCR>'))\n",
    "        for n in temp_jersey_number_arr:\n",
    "            predicted_jersey_numbers.append(n)\n",
    "    # find most common jersey number\n",
    "    maj_jersey_number = get_maj_jersey_number(predicted_jersey_numbers)\n",
    "    temp_row = [tracklet_fp, maj_jersey_number, candidate_team_ids, candidate_players_ids]\n",
    "    rows.append(temp_row)\n",
    "    \n",
    "# add all rows to df\n",
    "all_tracklet_features = pd.DataFrame(rows, columns=['tracklet_file_path', 'predicted_jersey_number', 'candidate_team_ids', 'candidate_player_ids'])\n",
    "all_tracklet_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_labels = []\n",
    "for file_path in all_tracklet_features['tracklet_file_path']:\n",
    "    video_name = file_path.split('/')[-2]\n",
    "    subtrack = file_path.split('/')[-1]\n",
    "    human_label = tracklet_human_annotations_dict[video_name]['tracks'][subtrack]['human_annotation']\n",
    "    human_labels.append(human_label)\n",
    "    \n",
    "all_tracklet_features['human_label'] = human_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JERSEY_VECTOR_SIZE = 500\n",
    "\n",
    "# 1. generate ground truth player embeddings\n",
    "jersey_numbers = list(set(ground_truth_player_features_subset_df['jersey_number'].astype(str)))\n",
    "sentences = [[char for char in number] for number in jersey_numbers]\n",
    "model = FastText(sentences, vector_size=JERSEY_VECTOR_SIZE, window=1, min_count=1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_team_ids = list(ground_truth_player_features_dict[k]['team_id'] for k in ground_truth_player_features_dict)\n",
    "unique_team_ids_idx_map = {str(int(team_id)): idx for idx, team_id in enumerate(unique_team_ids)}\n",
    "\n",
    "unique_player_ids_arr = sorted(ground_truth_player_features_subset_df['player_id'].unique())\n",
    "unique_player_ids_idx_map = {player_id: idx for idx, player_id in enumerate(unique_player_ids_arr)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jersey_number_embed(number: str):\n",
    "    if not number:\n",
    "        return [-sys.maxsize + 1] * JERSEY_VECTOR_SIZE\n",
    "    return model.wv[number]\n",
    "\n",
    "def get_team_id_embed(team_ids: List[str]):\n",
    "    embedding = np.zeros(len(unique_team_ids_idx_map))\n",
    "    for team_id in team_ids:\n",
    "        team_idx = unique_team_ids_idx_map[str(team_id)]\n",
    "        embedding[team_idx] = 1\n",
    "    return embedding\n",
    "    \n",
    "def get_player_id_embed(player_ids: List[str]):\n",
    "    embedding = np.zeros(len(unique_player_ids_idx_map))\n",
    "    for player_id in player_ids:\n",
    "        player_idx = unique_player_ids_idx_map[player_id]\n",
    "        embedding[player_idx] = 1\n",
    "    return embedding\n",
    "\n",
    "def normalize_embeddings(embeddings):\n",
    "    return normalize(embeddings, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>jersey_number</th>\n",
       "      <th>player_in_game</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1610612738</td>\n",
       "      <td>202340</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.044721359549995794, -0.044721359549995794,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1610612738</td>\n",
       "      <td>203109</td>\n",
       "      <td>99</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.0005500481493427992, -0.0004607620234395495...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1610612738</td>\n",
       "      <td>203089</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.0004180342570888874, -0.000663657286698243...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1610612738</td>\n",
       "      <td>1626154</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.0005987632939214192, -0.000336613803565496...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610612738</td>\n",
       "      <td>201973</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.0018356590344703974, -0.000657910193779705...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      team_id  player_id  jersey_number  player_in_game  \\\n",
       "0  1610612738     202340              0           False   \n",
       "1  1610612738     203109             99           False   \n",
       "2  1610612738     203089             30           False   \n",
       "3  1610612738    1626154             28           False   \n",
       "4  1610612738     201973              8           False   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.044721359549995794, -0.044721359549995794,...  \n",
       "1  [0.0005500481493427992, -0.0004607620234395495...  \n",
       "2  [-0.0004180342570888874, -0.000663657286698243...  \n",
       "3  [-0.0005987632939214192, -0.000336613803565496...  \n",
       "4  [-0.0018356590344703974, -0.000657910193779705...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten the player IDs and then one-hot encode\n",
    "player_id_encoder = OneHotEncoder(categories=[unique_player_ids_arr], sparse=False)\n",
    "player_id_encoder.fit(np.array(unique_player_ids_arr).reshape(-1, 1))  # fit the encoder\n",
    "\n",
    "def get_player_id_embed_one_hot(player_ids: List[str], encoder):\n",
    "    encoded = encoder.transform(np.array(list(player_ids)).reshape(-1, 1))\n",
    "    return encoded.sum(axis=0)  # sum to get a single vector representing all candidate IDs\n",
    "    \n",
    "ground_truth_player_embeddings = []\n",
    "for row in ground_truth_player_features_subset_df.itertuples():\n",
    "    jersey_number = row.jersey_number\n",
    "    # a. get jersey number embed\n",
    "    jersey_number_embedding = get_jersey_number_embed(jersey_number)\n",
    "    # b. get player id embeds\n",
    "    player_ids = [row.player_id]\n",
    "    player_id_embedding = get_player_id_embed_one_hot(player_ids, player_id_encoder)\n",
    "    # c. get concatinated embedding\n",
    "    concatinated_embedding = np.hstack([jersey_number_embedding, player_id_embedding])\n",
    "    ground_truth_player_embeddings.append(concatinated_embedding)\n",
    "\n",
    "ground_truth_player_embeddings = normalize_embeddings(ground_truth_player_embeddings)\n",
    "ground_truth_player_features_subset_df['embedding'] = [np.ravel(embedding) for embedding in ground_truth_player_embeddings]\n",
    "ground_truth_player_features_subset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. generated tracklet embeddings\n",
    "tracklet_embeddings = []\n",
    "for row in all_tracklet_features.itertuples():\n",
    "    jersey_number = row.predicted_jersey_number\n",
    "    candidate_player_ids = row.candidate_player_ids\n",
    "    # a. get jersey number embed\n",
    "    jersey_number_embedding = get_jersey_number_embed(jersey_number)\n",
    "    # b. get player id embeds\n",
    "    player_ids_embedding = get_player_id_embed_one_hot(list(candidate_player_ids), player_id_encoder)\n",
    "    # c. get concatinated embedding\n",
    "    concatinated_embedding = np.concatenate([jersey_number_embedding, player_ids_embedding])\n",
    "    tracklet_embeddings.append(concatinated_embedding)\n",
    "    \n",
    "tracklet_embeddings = normalize_embeddings(tracklet_embeddings)\n",
    "all_tracklet_features['embedding'] = [np.ravel(embedding) for embedding in tracklet_embeddings]\n",
    "all_tracklet_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_tracklet_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euclidean Distance\n",
    "def euclidean_distance(vec1: List[float], vec2: List[float]) -> float:\n",
    "    return math.sqrt(sum((x - y) ** 2 for x, y in zip(vec1, vec2)))\n",
    "\n",
    "# cosine Similarity\n",
    "def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:\n",
    "    dot_product = sum(x * y for x, y in zip(vec1, vec2))\n",
    "    magnitude1 = math.sqrt(sum(x ** 2 for x in vec1))\n",
    "    magnitude2 = math.sqrt(sum(y ** 2 for y in vec2))\n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        return 0.0  # Avoid division by zero\n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "def pearson_correlation(vec1: List[float], vec2: List[float]) -> float:\n",
    "    n = len(vec1)\n",
    "    sum1 = sum(vec1)\n",
    "    sum2 = sum(vec2)\n",
    "    sum1_sq = sum(x ** 2 for x in vec1)\n",
    "    sum2_sq = sum(y ** 2 for y in vec2)\n",
    "    product_sum = sum(x * y for x, y in zip(vec1, vec2))\n",
    "    \n",
    "    numerator = product_sum - (sum1 * sum2 / n)\n",
    "    denominator = math.sqrt((sum1_sq - sum1 ** 2 / n) * (sum2_sq - sum2 ** 2 / n))\n",
    "    if denominator == 0:\n",
    "        return 0.0  # Avoid division by zero\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Match Tracklet Embeddings to Candidates**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the result list with NaNs\n",
    "reidentified_tracklet_player_ids = [np.nan] * len(human_labels)\n",
    "\n",
    "# Extract ground truth player embeddings and IDs\n",
    "ground_truth_embeddings = np.vstack(ground_truth_player_features_subset_df['embedding'].values)\n",
    "ground_truth_player_ids = ground_truth_player_features_subset_df['player_id'].values\n",
    "\n",
    "# Iterate over tracklet features\n",
    "for tracklet_index, tracklet_row in enumerate(all_tracklet_features.itertuples()):\n",
    "    tracklet_embedding = np.array(tracklet_row.embedding).reshape(1, -1)\n",
    "    \n",
    "    # Compute distances to all ground truth embeddings\n",
    "    distances = cdist(tracklet_embedding, ground_truth_embeddings, metric='euclidean')\n",
    "    \n",
    "    # Find the index of the best match\n",
    "    best_match_idx = np.argmin(distances)\n",
    "    best_match_player_id = ground_truth_player_ids[best_match_idx]\n",
    "    \n",
    "    # Assign the best match player ID\n",
    "    reidentified_tracklet_player_ids[tracklet_index] = best_match_player_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with all predictions\n",
    "predictions_computed = pd.DataFrame({'tracklet_file_path': all_tracklet_features['tracklet_file_path'], 'human_label': human_labels, 'prediction': reidentified_tracklet_player_ids})\n",
    "predictions_computed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all matching predictions\n",
    "matched_mask = predictions_computed['human_label'] == predictions_computed['prediction']\n",
    "predictions_computed_matched = predictions_computed[matched_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all ids to floats\n",
    "predictions_computed_no_na = predictions_computed_matched.dropna()\n",
    "predictions_computed_no_na['human_label'] = predictions_computed_no_na['human_label'].astype(int)\n",
    "predictions_computed_no_na['prediction'] = predictions_computed_no_na['prediction'].astype(int)\n",
    "\n",
    "# find all matching predictions\n",
    "matched_mask = abs(predictions_computed_no_na['human_label'] - predictions_computed_no_na['prediction']) < 0.5\n",
    "predictions_no_na_matched = predictions_computed_no_na[matched_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions_no_na_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
