{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "ground_truth_player_features_fp = '/playpen-storage/levlevi/player-re-id/src/data/raw_features.json'\n",
    "ground_truth_player_features_df_fp = '/playpen-storage/levlevi/player-re-id/src/data/team_rosters_df.csv'\n",
    "with open(ground_truth_player_features_fp, 'r') as f:\n",
    "    ground_truth_player_features_dict = json.load(f)\n",
    "ground_truth_player_features_df = pd.read_csv(ground_truth_player_features_df_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_626371/1631618499.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ground_truth_player_features_subset_df['player_in_game'] = [False] * len(ground_truth_player_features_subset_df)\n"
     ]
    }
   ],
   "source": [
    "# which features are redundant?\n",
    "ground_truth_player_features_subset_df = ground_truth_player_features_df[['team_id', 'player_id', 'jersey_number']]\n",
    "\n",
    "# add feature to indicate if player is in game\n",
    "ground_truth_player_features_subset_df['player_in_game'] = [False] * len(ground_truth_player_features_subset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Format Tracklet Predicted Features**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# how can we convert model predictions to feature vectors?\n",
    "# human labels for 50 tracklet test set\n",
    "with open('/playpen-storage/levlevi/player-re-id/src/data/_50_game_reid_benchmark_/annotations.json') as f:\n",
    "    tracklet_human_annotations_dict = json.load(f)\n",
    "    \n",
    "# convert raw florence preditions to dict\n",
    "florence_predictions_fp = '/playpen-storage/levlevi/player-re-id/src/data/florence_100_track_bm_results.json'\n",
    "def read_florence_predictions(fp):\n",
    "    with open(fp, 'r') as f:\n",
    "        florence_predictions = f.readlines()\n",
    "    predictions = {}\n",
    "    for p in florence_predictions:\n",
    "        key = p.split(':')[0]\n",
    "        values = ast.literal_eval('{' + '{'.join(p.split('{')[1: ]))\n",
    "        predictions[key] = values\n",
    "    return predictions\n",
    "predicted_tracklet_features_florence_dict = read_florence_predictions(florence_predictions_fp)\n",
    "\n",
    "# roster metadata\n",
    "with open(\"/playpen-storage/levlevi/player-re-id/src/data/raw_features.json\", 'r') as f:\n",
    "    ground_truth_player_features_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from collections import Counter\n",
    "\n",
    "# get most common race from list\n",
    "def get_maj_race(races):\n",
    "    if len(races) == 0:\n",
    "        return None\n",
    "    counter = Counter(races)\n",
    "    return counter.most_common(1)[0][0]\n",
    "\n",
    "# get most common player postion from list\n",
    "def get_maj_position(positions):\n",
    "    if len(positions) == 0:\n",
    "        return None\n",
    "    counter = Counter(positions)\n",
    "    return counter.most_common(1)[0][0]\n",
    "\n",
    "# get most common jersey number from list\n",
    "def get_maj_jersey_number(jersey_numbers):\n",
    "    if len(jersey_numbers) == 0:\n",
    "        return None\n",
    "    counter = Counter(jersey_numbers)\n",
    "    return counter.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "HUDL_GAME_LOGS_DIR = '/mnt/sun/levlevi/nba-plus-statvu-dataset/hudl-game-logs'\n",
    "# id: fp\n",
    "game_logs_map = {\n",
    "    f.split('.')[-2]: os.path.join(HUDL_GAME_LOGS_DIR, f) for f in os.listdir(HUDL_GAME_LOGS_DIR)\n",
    "}\n",
    "\n",
    "def calculate_string_similarity_score(string_one, string_two):\n",
    "    return SequenceMatcher(None, string_one, string_two).ratio()\n",
    "\n",
    "def find_closest_player_id(player_name: str) -> str:\n",
    "    best_similarity = -100\n",
    "    best_player_id_match = None\n",
    "    best_match_name = ''\n",
    "    for team in ground_truth_player_features_dict:\n",
    "        for player in ground_truth_player_features_dict[team]['players']:\n",
    "            cand_full_name = ''\n",
    "            if ',' not in player:\n",
    "                cand_full_name = player\n",
    "            else:\n",
    "                cand_full_name = player.split(',')[1] + ' ' + player.split(',')[0]\n",
    "            player_id = ground_truth_player_features_dict[team]['players'][player]['player_id']\n",
    "            similarity = calculate_string_similarity_score(cand_full_name, player_name)\n",
    "            if similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_player_id_match = player_id\n",
    "                best_match_name = cand_full_name\n",
    "    # sanity check\n",
    "    # print(player_name, best_match_name, best_similarity)\n",
    "    return int(best_player_id_match)\n",
    "\n",
    "def get_candidate_player_ids(tracklet_fp: str) -> List[str]:\n",
    "    game_id = tracklet_fp.split('/')[-2].split('_')[0]\n",
    "    period = tracklet_fp.split('/')[-2].split('_')[-1].split('period')[1][0]\n",
    "    period = int(period)\n",
    "    df = pd.read_csv(game_logs_map[game_id], delimiter=';')\n",
    "    df['is_period'] = df['half'].apply(lambda x: x == period)\n",
    "    df_period_matched = df[df['is_period'] == True]\n",
    "    \n",
    "    unique_player_ids = set()\n",
    "    unique_player_names = set(df['player_name'].unique())\n",
    "    unique_player_names = set(df_period_matched['player_name'].unique())\n",
    "    unique_player_names_no_nan = {p for p in unique_player_names if not pd.isna(p)}\n",
    "    for pn in unique_player_names_no_nan:\n",
    "        unique_player_ids.add(find_closest_player_id(pn))\n",
    "    return unique_player_ids\n",
    "\n",
    "def get_candidate_team_ids(tracklet_fp: str) -> List[str]:\n",
    "    team_one_name = tracklet_fp.split('/')[-2].split('_')[3].replace(\" \", \"_\")\n",
    "    team_two_name = tracklet_fp.split('/')[-2].split('_')[5].replace(\" \", \"_\")\n",
    "    team_one_id = ground_truth_player_features_dict[team_one_name]['team_id']\n",
    "    team_two_id = ground_truth_player_features_dict[team_two_name]['team_id']\n",
    "    return [team_one_id, team_two_id]\n",
    "\n",
    "# all rows in predictions df\n",
    "rows = []\n",
    "for tracklet_fp, raw_predictions in predicted_tracklet_features_florence_dict.items():\n",
    "    # get team ids from file path\n",
    "    predicted_jersey_numbers = []\n",
    "    candidate_team_ids = get_candidate_team_ids(tracklet_fp)\n",
    "    candidate_players_ids = get_candidate_player_ids(tracklet_fp)\n",
    "    # get jersey numbers\n",
    "    for frame_idx in raw_predictions:\n",
    "        # match all valid predictions\n",
    "        temp_jersey_number_arr = re.findall(r'\\d+', raw_predictions[frame_idx].get('<OCR>'))\n",
    "        for n in temp_jersey_number_arr:\n",
    "            predicted_jersey_numbers.append(n)\n",
    "    # find most common jersey number\n",
    "    maj_jersey_number = get_maj_jersey_number(predicted_jersey_numbers)\n",
    "    temp_row = [tracklet_fp, maj_jersey_number, candidate_team_ids, candidate_players_ids]\n",
    "    rows.append(temp_row)\n",
    "    \n",
    "# add all rows to df\n",
    "all_tracklet_features = pd.DataFrame(rows, columns=['tracklet_file_path', 'predicted_jersey_number', 'candidate_team_ids', 'candidate_player_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_labels = []\n",
    "for file_path in all_tracklet_features['tracklet_file_path']:\n",
    "    video_name = file_path.split('/')[-2]\n",
    "    subtrack = file_path.split('/')[-1]\n",
    "    human_label = tracklet_human_annotations_dict[video_name]['tracks'][subtrack]['human_annotation']\n",
    "    human_labels.append(human_label)\n",
    "    \n",
    "all_tracklet_features['human_label'] = human_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "from gensim.models import FastText\n",
    "\n",
    "JERSEY_VECTOR_SIZE = 300\n",
    "\n",
    "# 1. generate ground truth player embeddings\n",
    "ground_truth_player_embeddings = []\n",
    "\n",
    "jersey_numbers = list(set(ground_truth_player_features_subset_df['jersey_number'].astype(str)))\n",
    "sentences = [[char for char in number] for number in jersey_numbers]\n",
    "model = FastText(sentences, vector_size=JERSEY_VECTOR_SIZE, window=1, min_count=1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_team_ids = list(ground_truth_player_features_dict[k]['team_id'] for k in ground_truth_player_features_dict)\n",
    "unique_team_ids_idx_map = {str(int(team_id)): idx for idx, team_id in enumerate(unique_team_ids)}\n",
    "\n",
    "player_ids_arr = ground_truth_player_features_subset_df['player_id'].unique()\n",
    "player_ids_idx_map = {player_id: idx for idx, player_id in enumerate(player_ids_arr)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_626371/993517881.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ground_truth_player_features_subset_df['embedding'] = ground_truth_player_embeddings\n"
     ]
    }
   ],
   "source": [
    "def get_jersey_number_embed(number: str):\n",
    "    if not number:\n",
    "        return [-sys.maxsize + 1] * JERSEY_VECTOR_SIZE\n",
    "    return model.wv[number]\n",
    "\n",
    "def get_team_id_embed(team_ids: List[str]):\n",
    "    embedding = np.zeros(len(unique_team_ids_idx_map))\n",
    "    for team_id in team_ids:\n",
    "        team_idx = unique_team_ids_idx_map[str(team_id)]\n",
    "        embedding[team_idx] = 1\n",
    "    return embedding\n",
    "    \n",
    "def get_player_id_embed(player_ids: List[str]):\n",
    "    embedding = np.zeros(len(player_ids_idx_map))\n",
    "    for player_id in player_ids:\n",
    "        player_idx = player_ids_idx_map[player_id]\n",
    "        embedding[player_idx] = 1\n",
    "    return embedding\n",
    "    \n",
    "for row in ground_truth_player_features_subset_df.itertuples():\n",
    "    jersey_number = row.jersey_number\n",
    "    # a. get jersey number embed\n",
    "    jersey_number_embedding = get_jersey_number_embed(jersey_number)\n",
    "    # b. get team id embed\n",
    "    team_id = [row.team_id]\n",
    "    team_id_embedding = get_team_id_embed(team_id)\n",
    "    # c. get player id embeds\n",
    "    player_id = [row.player_id]\n",
    "    player_id_embedding = get_player_id_embed(player_id)\n",
    "    # d. get concatinated embedding\n",
    "    concatinated_embedding = np.concatenate([jersey_number_embedding, team_id_embedding, player_id_embedding])\n",
    "    ground_truth_player_embeddings.append(concatinated_embedding)\n",
    "    \n",
    "ground_truth_player_features_subset_df['embedding'] = ground_truth_player_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tracklet_file_path</th>\n",
       "      <th>predicted_jersey_number</th>\n",
       "      <th>candidate_team_ids</th>\n",
       "      <th>candidate_player_ids</th>\n",
       "      <th>human_label</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/opr/levlevi/player-re-id/src/data/_50_gam...</td>\n",
       "      <td>33</td>\n",
       "      <td>[1610612749, 1610612746]</td>\n",
       "      <td>{201601, 203948, 203953, 200755, 1718, 2746, 1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.015987707301974297, -0.009612071327865124, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/opr/levlevi/player-re-id/src/data/_50_gam...</td>\n",
       "      <td>None</td>\n",
       "      <td>[1610612749, 1610612746]</td>\n",
       "      <td>{201601, 203948, 203953, 200755, 1718, 2746, 1...</td>\n",
       "      <td>203114.0</td>\n",
       "      <td>[-9.223372036854776e+18, -9.223372036854776e+1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/opr/levlevi/player-re-id/src/data/_50_gam...</td>\n",
       "      <td>None</td>\n",
       "      <td>[1610612749, 1610612746]</td>\n",
       "      <td>{201601, 203948, 203953, 200755, 1718, 2746, 1...</td>\n",
       "      <td>200755.0</td>\n",
       "      <td>[-9.223372036854776e+18, -9.223372036854776e+1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/opr/levlevi/player-re-id/src/data/_50_gam...</td>\n",
       "      <td>22</td>\n",
       "      <td>[1610612749, 1610612746]</td>\n",
       "      <td>{201601, 203948, 203953, 200755, 1718, 2746, 1...</td>\n",
       "      <td>203114.0</td>\n",
       "      <td>[0.007096998859196901, 0.013843805529177189, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/opr/levlevi/player-re-id/src/data/_50_gam...</td>\n",
       "      <td>2</td>\n",
       "      <td>[1610612749, 1610612746]</td>\n",
       "      <td>{201601, 203948, 203953, 200755, 1718, 2746, 1...</td>\n",
       "      <td>203114.0</td>\n",
       "      <td>[0.004819462541490793, -0.014067944139242172, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tracklet_file_path predicted_jersey_number  \\\n",
       "0  /mnt/opr/levlevi/player-re-id/src/data/_50_gam...                      33   \n",
       "1  /mnt/opr/levlevi/player-re-id/src/data/_50_gam...                    None   \n",
       "2  /mnt/opr/levlevi/player-re-id/src/data/_50_gam...                    None   \n",
       "3  /mnt/opr/levlevi/player-re-id/src/data/_50_gam...                      22   \n",
       "4  /mnt/opr/levlevi/player-re-id/src/data/_50_gam...                       2   \n",
       "\n",
       "         candidate_team_ids  \\\n",
       "0  [1610612749, 1610612746]   \n",
       "1  [1610612749, 1610612746]   \n",
       "2  [1610612749, 1610612746]   \n",
       "3  [1610612749, 1610612746]   \n",
       "4  [1610612749, 1610612746]   \n",
       "\n",
       "                                candidate_player_ids  human_label  \\\n",
       "0  {201601, 203948, 203953, 200755, 1718, 2746, 1...          NaN   \n",
       "1  {201601, 203948, 203953, 200755, 1718, 2746, 1...     203114.0   \n",
       "2  {201601, 203948, 203953, 200755, 1718, 2746, 1...     200755.0   \n",
       "3  {201601, 203948, 203953, 200755, 1718, 2746, 1...     203114.0   \n",
       "4  {201601, 203948, 203953, 200755, 1718, 2746, 1...     203114.0   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.015987707301974297, -0.009612071327865124, ...  \n",
       "1  [-9.223372036854776e+18, -9.223372036854776e+1...  \n",
       "2  [-9.223372036854776e+18, -9.223372036854776e+1...  \n",
       "3  [0.007096998859196901, 0.013843805529177189, -...  \n",
       "4  [0.004819462541490793, -0.014067944139242172, ...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. generated tracklet embeddings\n",
    "tracklet_embeddings = []\n",
    "for row in all_tracklet_features.itertuples():\n",
    "    jersey_number = row.predicted_jersey_number\n",
    "    team_ids = row.candidate_team_ids\n",
    "    candidate_player_ids = row.candidate_player_ids\n",
    "    # a. get jersey number embed\n",
    "    jersey_number_embedding = get_jersey_number_embed(jersey_number)\n",
    "    # b. get team id embed\n",
    "    team_id_embedding = get_team_id_embed(team_ids)\n",
    "    # c. get player id embeds\n",
    "    player_ids_embedding = get_player_id_embed(list(candidate_player_ids))\n",
    "    # d. get concatinated embedding\n",
    "    concatinated_embedding = np.concatenate([jersey_number_embedding, team_id_embedding, player_ids_embedding])\n",
    "    tracklet_embeddings.append(concatinated_embedding)\n",
    "    \n",
    "all_tracklet_features['embedding'] = tracklet_embeddings\n",
    "all_tracklet_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euclidean Distance\n",
    "def euclidean_distance(vec1: List[float], vec2: List[float]) -> float:\n",
    "    return math.sqrt(sum((x - y) ** 2 for x, y in zip(vec1, vec2)))\n",
    "\n",
    "# cosine Similarity\n",
    "def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:\n",
    "    dot_product = sum(x * y for x, y in zip(vec1, vec2))\n",
    "    magnitude1 = math.sqrt(sum(x ** 2 for x in vec1))\n",
    "    magnitude2 = math.sqrt(sum(y ** 2 for y in vec2))\n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        return 0.0  # Avoid division by zero\n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "def pearson_correlation(vec1: List[float], vec2: List[float]) -> float:\n",
    "    n = len(vec1)\n",
    "    sum1 = sum(vec1)\n",
    "    sum2 = sum(vec2)\n",
    "    sum1_sq = sum(x ** 2 for x in vec1)\n",
    "    sum2_sq = sum(y ** 2 for y in vec2)\n",
    "    product_sum = sum(x * y for x, y in zip(vec1, vec2))\n",
    "    \n",
    "    numerator = product_sum - (sum1 * sum2 / n)\n",
    "    denominator = math.sqrt((sum1_sq - sum1 ** 2 / n) * (sum2_sq - sum2 ** 2 / n))\n",
    "    if denominator == 0:\n",
    "        return 0.0  # Avoid division by zero\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Match Tracklet Embeddings to Candidates**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vector(arr):\n",
    "    mean = np.mean(arr)\n",
    "    std = np.std(arr)\n",
    "    return (arr - mean) / std\n",
    "    \n",
    "# for each tracklet, generate a feature vector\n",
    "tracklet_index = 0\n",
    "reidentified_tracklet_player_ids = [np.nan] * len(human_labels)\n",
    "for tracklet_row in all_tracklet_features.itertuples():\n",
    "    tracklet_embedding = np.array(tracklet_row.embedding)\n",
    "    best_score = - sys.maxsize + 1\n",
    "    best_match_idx = np.nan\n",
    "    for row in ground_truth_player_features_subset_df.itertuples():\n",
    "        candidate_player_embedding = np.array(row.embedding)\n",
    "        # normalize\n",
    "        v1 = normalize_vector(tracklet_embedding)\n",
    "        v2 = normalize_vector(candidate_player_embedding)\n",
    "        # compute similarity\n",
    "        score = cosine_similarity(tracklet_embedding, candidate_player_embedding)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match_player_id = row.player_id\n",
    "            \n",
    "    # print(best_match_player_id)\n",
    "    reidentified_tracklet_player_ids[tracklet_index] = best_match_player_id\n",
    "    tracklet_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tracklet_file_path</th>\n",
       "      <th>human_label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/opr/levlevi/player-re-id/src/data/_50_gam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/opr/levlevi/player-re-id/src/data/_50_gam...</td>\n",
       "      <td>203114.0</td>\n",
       "      <td>202340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/opr/levlevi/player-re-id/src/data/_50_gam...</td>\n",
       "      <td>200755.0</td>\n",
       "      <td>202340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/opr/levlevi/player-re-id/src/data/_50_gam...</td>\n",
       "      <td>203114.0</td>\n",
       "      <td>203114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/opr/levlevi/player-re-id/src/data/_50_gam...</td>\n",
       "      <td>203114.0</td>\n",
       "      <td>2037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  tracklet_file_path  human_label  prediction\n",
       "0  /mnt/opr/levlevi/player-re-id/src/data/_50_gam...          NaN      202325\n",
       "1  /mnt/opr/levlevi/player-re-id/src/data/_50_gam...     203114.0      202340\n",
       "2  /mnt/opr/levlevi/player-re-id/src/data/_50_gam...     200755.0      202340\n",
       "3  /mnt/opr/levlevi/player-re-id/src/data/_50_gam...     203114.0      203114\n",
       "4  /mnt/opr/levlevi/player-re-id/src/data/_50_gam...     203114.0        2037"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe with all predictions\n",
    "predictions_computed = pd.DataFrame({'tracklet_file_path': all_tracklet_features['tracklet_file_path'], 'human_label': human_labels, 'prediction': reidentified_tracklet_player_ids})\n",
    "predictions_computed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all matching predictions\n",
    "matched_mask = predictions_computed['human_label'] == predictions_computed['prediction']\n",
    "predictions_computed_matched = predictions_computed[matched_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all ids to floats\n",
    "predictions_computed_no_na = predictions_computed_matched.dropna()\n",
    "predictions_computed_no_na['human_label'] = predictions_computed_no_na['human_label'].astype(int)\n",
    "predictions_computed_no_na['prediction'] = predictions_computed_no_na['prediction'].astype(int)\n",
    "\n",
    "# find all matching predictions\n",
    "matched_mask = abs(predictions_computed_no_na['human_label'] - predictions_computed_no_na['prediction']) < 0.5\n",
    "predictions_no_na_matched = predictions_computed_no_na[matched_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_no_na_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730951 2.0 2.449489742783178\n"
     ]
    }
   ],
   "source": [
    "v1 = np.array([1, 0, 0, 0, 1, 0, 1]).astype(np.float32)\n",
    "v2 = np.array([0, 1, 0, 1, 0, 1, 0]).astype(np.float32)\n",
    "v3 = np.array([0, 0, 1, 0, 1, 1, 0]).astype(np.float32)\n",
    "c1 = np.array([1, 1, 0, 1, 1, 0, 1]).astype(np.float32)\n",
    "\n",
    "print(euclidean_distance(c1, v1), euclidean_distance(c1, v2), euclidean_distance(c1, v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
